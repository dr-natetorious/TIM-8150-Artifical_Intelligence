# Readings

## AI for All: Drawing Women into the Artificial Intelligence Field (2018)

Prives, L. (2018). AI for all: Drawing women into the artificial intelligence field. IEEE Women in Engineering Magazine, 12(2), 30-32. Dec. 2018, doi: 10.1109/MWIE.2018.2866890. [AI_for_all.pdf](AI_for_all.pdf).

The article tells the story of `Benna Ammanatha`, who started the _Women for AI_ to promote the tech industry toward more diversity and inclusion.  

> "We  put  a  lot  of  focus  on  computer  programming  right  now,  but  the  type  of  programming  we  do  today  will go away," predicts Ammanath. "With the  advances  in  voice  recognition,  you  might be able to just describe something to  an  AI  product,  and  it  will  program  for  you."  Before  we  get  there,  though,  Ammanath says, "I think it’s important for my kids to understand how Alexa and Siri actually work."

## Artificial Intelligence: Are We All Going to Be Unemployed (2018)

A. Sandybayev, "Artificial Intelligence: Are We All Going to Be Unemployed?," 2018 Fifth HCT Information Technology Trends (ITT), Dubai, United Arab Emirates, 2018, pp. 23-27, doi: 10.1109/CTIT.2018.8649521. [AI_and_unemployment](AI_and_unemployment.pdf).

According to Pricewaterhouse Coopers, new technologies will cut specific job markets, perhaps by 20%.  However, those same technologies will grow the spectrum of new opportunities.  For instance, people that have a disability, learning impedement, or communication deficiency might no longer be handicapped.

One of the challenges with this statement, is that the evolution of machines crosses mechanical to technical to feelings (see Feelings Paper Week1).  This means that during the initial phase, machines are doing to displace low-skilled worker numbers without addressing the job creation that follows in step 2.

## Artificial Intelligence in Politics: Establishing Ethics (2019)

T. B. Kane, "Artificial Intelligence in Politics: Establishing Ethics," in IEEE Technology and Society Magazine, vol. 38, no. 1, pp. 72-80, March 2019, doi: 10.1109/MTS.2019.2894474. [AI_in_Politics.pdf](AI_in_Politics.pdf).

The article describes the impact of social media advertising systems, like Facebook on election cycles.

> A Facebook digital marketing strategy tends to be a `Segmentation-Targeting-Positioning`  (STP)  strategy  [4],  whereby,  a  marketing  team  will  use  tools  to  segment  a  population  into  different  groups  according  to  various  characteristics,  such as, for example male, single father, age under 30. Tar-geting  is  the  process  of  selecting  one  or  more  of  the  seg-ments  to  work  on.  Positioning  is  the  process  of  detailing  how members of the segment will be approached and what strategy will be used to bring the task to completion. Face-book  allows  business  customers  to  position  materials  directly  to  Facebook  users  while  they  are  active  in  their  social networks, and even while they are on other platforms.

The authors continue with a focus on _Facebook for Politics_ (FfP) specifically noting:

> The  approach  adopted  here  is  to  view  social  network-ing  activities  from  a  theatrical  perspective  and  to  explore  the  steps  of  FfP  activity  as  play-within-a-play  activity  from  an  advanced  black-box  AI  entity.  The  FfP  black-box  entity  is compared with the Searle black-box entity and allows us to  draw  distinctions  that  posit  FfP  as  an  artificial  person  with  co-opted  features  of  human  intelligence.  This  paper  concludes  that  powerful  sociotechnical  AI  tools  such  as  FfP cannot be understood as traditional standalone AI sys-tems  and  need  to  be  policed  as  would  any  human  being  who  had  interests  and  abilities  to  influence  the  voting  intentions  of  hundreds  of  thousands  of  voters  simultaneously.

## Automation, per se, is not job elimination: How artificial intelligence forwards cooperative human-machine coexistence (2017)

O. H. Hamid, N. L. Smith and A. Barzanji, "Automation, per se, is not job elimination: How artificial intelligence forwards cooperative human-machine coexistence," 2017 IEEE 15th International Conference on Industrial Informatics (INDIN), Emden, 2017, pp. 899-904, doi: 10.1109/INDIN.2017.8104891. [AI_and_cooperation.pdf](AI_and_cooperation.pdf).

> Despite the gloomy scenario of automationas a job eliminator, we argue humans and machines can cross-fertilise in a way that  forwards  a  cooperative  coexistence.  Webuild our argument on three pillars: (i) the economic mechanism of  automation,  (ii) the dichotomy of  'experience' that separatesthe first-person perspective of humans from artificial learningalgorithms, and (iii)  the  interdependent  relationship betweenhumans and machines.

There is a lot of debate around the potential benefits of increased automation, however there is a common fear that these increases to productivity will _cause the rich to get richer and the poor to get poorer_.

> Predictions for jobs at risk range from a figureof 9% in the upcoming 1-2 decades to 47%[4]. It  is worthsaying that many jobs are  likely to change but not disappearowing to the automation of associated tasks [13]. In addition, it appears wage inequality between high- and low-skilled jobs will  exacerbate.  For instance, in the U.S. AI would pressure 83% of jobs paying $20or less an hour in contrast to  only 4% paying $40 or more (pg 899).

The `robot density` is an international benchmark that compares the number of robotic units deployed in the labor market per 10k human employees (see Figure 2).  While this is leading to an uptick in unemployement in specific areas like Bank Tellers -- it also enhances other aspects like Amazon fulfillment centers.

![robot_density.png](robot_density.png)

There are numerous examples of where human enhanced systems are superior to raw artificial intelligence.

> The  argument  had  always  beenthat machine intelligence playing chess against a human GrandMaster  was  merely  a  combination  of  computational  prowessand  probabilistic  search  algorithms.  Kasparov  suggested  ex-tending  the game  through what  was called  ‘advanced chess’,a version in which human players play against each other whilebeing assisted by computer software. Each of the games lastedfor  60 minutes,  which meant  that a  human player  had  to cutthe search algorithm when it took longer than it should have inorder not to lose technically. The surprising result was that atournament organized in 1998 was won by a team of amateurswho were skilled at integrating machine assistance [36]. Smartamateurs could even beat Hydra, a supercomputer better thanDeep Blue, by using analytic skill sets. It was thecombinationof strategic guidance with tactical acuity that gave victory.

## EU Ethics Guidelines for Trustworthy AI (2019)

European Union (8 April 2019). EU Ethics Guidelines for Trustworthy AI. [WebSite](https://ec.europa.eu/futurium/en/ai-alliance-consultation). [EthicsGuidelinesforTrustworthyAI](EthicsGuidelinesforTrustworthyAI.pdf).

> The  aim  of the Guidelinesis  to promote TrustworthyAI. TrustworthyAI  has **three components**,  which  should  be met  throughout  the  system's  entire  life  cycle:(1) it  should  be **lawful**, complying  withall applicable  lawsandregulations(2) it should be **ethical**, ensuringadherence toethical principles and values and (3) it should be **robust**, both  from  a  technical  and  social  perspectivesince, even  with  good  intentions,  AI  systems  can  cause  unintentional harm. Each  component in  itself is  necessary  but  not  sufficient for  the  achievement  ofTrustworthyAI.  Ideally,  all threecomponents  work  in  harmony  and  overlap  in  their  operation. If,  in  practice,  tensions  arise  between  these components, society should endeavourto align them.

## A legal perspective on the trials and tribulations of AI: how artificial intelligence, the internet of things, smart contracts, and other technologies will affect the law (2018)

Giuffrida, I., Lederer, F., & Vermeys, N. (2018). A Legal Perspective on the Trials and Tribulations of Ai: How Artificial Intelligence, the Internet of Things, Smart Contracts, and Other Technologies Will Affect the Law. Case Western Reserve Law Review, 68(3), 747–781. [EBSCO](https://search-ebscohost-com.proxy1.ncu.edu/login.aspx?direct=true&db=tsh&AN=130372095&site=eds-live). [Legal_and_AI.pdf](Legal_and_AI.pdf).

With every technology there are legal challenges that come from attempting to fit the abstract concepts into the complex and opaque legal language which has exactly one-meaning per word.  These discrepencies introduce requirements into artifical intelligence systems that do not always make sense.

> The  principal  difficulty  which  this  case  has  given  me  arises from  the  anthropomorphic  character  of  virtually  everything that  is  thought  or  said  or  written  about  computers. Words    like   “language”,    “memory”,    “understand”, “instruction”,  “read”,  “write”,  “command”,  and  many  others are  in  constant  use.  They  are  words  which,  in  their  primary meaning,  have  reference  to  cognitive  beings.  Computers  are not  cognitive.  The  metaphors  and  analogies  which  we  use  to describe their functions remain just that. (pg. 756)

For instance, Google's algorithms erroneously declared Obama was a muslim.  Should they be liable for slander or some other tort? On the one hand, the technology is spreading misinformation.  On the other hand, its a aggregation service that sees the world as patterns of 1s and 0s.

> Accordingly, the effective accuracy of an algorithm is dependent on both  the  programming  and  the  data.  This  dictates  a  further,  legally- troubling  conclusion.  If there  are  doubts  about  the  results  of an  algo­rithm,  one  can  at  least  theoretically  inspect  and  analyze  the  pro­gramming  that  makes  up  the  algorithm.  Given  the  volume  of  data available on the Internet, however,  it  may be impossible to adequately determine and inspect the data used by the algorithm (pg 755)

## Information Accountability Foundation (2020)

Information Accountability Foundation (2020). [WebSite](https://informationaccountability.org/publications/).

> This website is a global information policy think tank that works with regulatory authorities, policymakers, business leaders, civil society, and other key stakeholders around the world to help frame and advance data protection law and practice through accountability-based information governance.

## OECD Principles of Ethical AI (2019)

OECD (2019). OECD Principles of Ethical AI. Recommendation of the Council on Artificial Intelligence. [OECD.org](https://www.oecd.org/legal/legal-instruments.htm). [OECD-LEGAL-0449-en.pdf](OECD-LEGAL-0449-en.pdf).

The short read outlines a recommended model for governments to think about AI, based on experts spanning 50 interdeciplenary areas.  The mantra is similar to the EU's requests that policies have/contain:

- Human centred values and fairness
- Transparency and explainability
- Robustness, security, and safety
- Accountability

## Robots and AI at work: the prospects for singularity (2018)

Upchurch, M. (2018). Robots and AI at work: the prospects for singularity. New Technology, Work & Employment, 33(3), 205–218. doi:10.1111/ntwe.12124. [Robots_at_work.pdf](Robots_at_work.pdf).

> This paper address emerging debates and controversies on the impact of robots and artificial intelligence on the world of work.
