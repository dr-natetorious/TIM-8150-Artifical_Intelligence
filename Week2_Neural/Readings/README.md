# Readings

## Fundamentals of Computational Intelligence

- Read: [Chapters 2, 3, and 5](../Book_FundCompIntel)

## Model Compression and Acceleration for Deep Neural Networks: The Principles, Progress, and Challenges (2018)

Y. Cheng, D. Wang, P. Zhou and T. Zhang, "Model Compression and Acceleration for Deep Neural Networks: The Principles, Progress, and Challenges," in IEEE Signal Processing Magazine, vol. 35, no. 1, pp. 126-136, Jan. 2018,  [DOI](https://doi-org.proxy1.ncu.edu/10.1109/MSP.2017.2765695). [ModelCompression.pdf](ModelCompression.pdf).

> This paper discusses how the high computational capacity of modern hardware and software enables the application of deep neural networks with millions or even billions of parameters.

## Survey of Progress in Deep Neural Networks (2017)

Stuart, M., & Manic, M. (2017). Survey of progress in deep neural networks for resource-constrained applications. IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society, Industrial Electronics Society, IECON 2017 - 43rd Annual Conference of the IEEE. 2017:7259. [DOI](https://doi-org.proxy1.ncu.edu/10.1109/IECON.2017.8217271). [ResourceConstrained.pdf](ResourceConstrained.pdf).  

> This survey examines efforts that target the challenges of implementing energy-efficient, low cost, and accurate neural network models. Approaches come in many forms, with solutions ranging from software optimization to hardware reorganization.
